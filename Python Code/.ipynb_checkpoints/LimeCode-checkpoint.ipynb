{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook run using keras: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import os\n",
    "import skimage.io as io\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt \n",
    "from keras import layers\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "print('Notebook run using keras:', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (7, 7), padding='same',input_shape=(240,240,3),strides=(1, 1)))\n",
    "\n",
    "    # Conv2D network, output = 64, filter = 7 x 7, strides = 1 x 1, activation = ReLU, padding=same\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (7, 7)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "    # Conv2D network, output = 32, filter = 7 x 7, strides = 1 x 1, activation = ReLU, padding=same\n",
    "    model.add(Conv2D(32, (7, 7), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\\\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_model_lm(learn_rate=0.01, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (7, 7), padding='same',input_shape=input_shape,strides=(1, 1)))\n",
    "\n",
    "    # Conv2D network, output = 64, filter = 7 x 7, strides = 1 x 1, activation = ReLU, padding=same\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (7, 7)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "    # Conv2D network, output = 32, filter = 7 x 7, strides = 1 x 1, activation = ReLU, padding=same\n",
    "    model.add(Conv2D(32, (7, 7), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\\\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    optimizer = keras.optimizers.Adam(lr=learn_rate, beta_1=momentum)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = create_model()\n",
    "inet_model = model.load_weights('./brain_tumour_model.h5')\n",
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for img_path in path_list:\n",
    "        img = image.load_img(img_path, target_size=(240, 240,3))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x/255\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        out.append(x)\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'C:\\\\Users\\\\abhis\\\\Downloads\\\\HeatTracker\\\\Brain Tumour Project\\\\Yes\\\\desktop.ini'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-908e430143ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\abhis\\\\Downloads\\\\HeatTracker\\\\Brain Tumour Project\\\\Yes\\\\\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# I'm dividing by 2 and adding 0.5 because of how this Inception represents images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_img_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\abhis\\\\Downloads\\\\HeatTracker\\\\Brain Tumour Project\\\\Yes\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-967b016d9d21>\u001b[0m in \u001b[0;36mtransform_img_fn\u001b[1;34m(path_list)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\work\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'L'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\work\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2929\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2930\u001b[0m     raise UnidentifiedImageError(\n\u001b[1;32m-> 2931\u001b[1;33m         \u001b[1;34m\"cannot identify image file %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2932\u001b[0m     )\n\u001b[0;32m   2933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'C:\\\\Users\\\\abhis\\\\Downloads\\\\HeatTracker\\\\Brain Tumour Project\\\\Yes\\\\desktop.ini'"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"C:\\\\Users\\\\abhis\\\\Downloads\\\\HeatTracker\\\\Brain Tumour Project\\\\Yes\\\\\"):\n",
    "    # I'm dividing by 2 and adding 0.5 because of how this Inception represents images\n",
    "    images = transform_img_fn([os.path.join(\"C:\\\\Users\\\\abhis\\\\Downloads\\\\HeatTracker\\\\Brain Tumour Project\\\\Yes\\\\\", file)])\n",
    "    images = np.squeeze(images,axis=0)\n",
    "    plt.imshow(images[0] / 2 + 0.5)\n",
    "    inet_model.summary()\n",
    "\n",
    "    # Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels\n",
    "    explainer = lime_image.LimeImageExplainer(random_state=42)\n",
    "\n",
    "    images = images.astype('double')\n",
    "    explanation = explainer.explain_instance(images[0], inet_model.predict, top_labels=5, hide_color=0, num_samples=1000)\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "    io.imsave(os.path.join(\"C://Users//abhis//Downloads//HeatTracker//Brain Tumour Project//Lime Images//\", file), mark_boundaries(temp / 2 + 0.5, mask),quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
